{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Importação de bibliotecas\n",
    "# ========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import inspect\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35067ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Carregamento do dataset\n",
    "dataset = pd.read_csv(\"../data/creditcard.csv\")\n",
    "\n",
    "# Converte todos os nomes de colunas para minúsculas\n",
    "dataset.columns = dataset.columns.str.lower()\n",
    "\n",
    "# Criação do diretório para salvar gráficos\n",
    "os.makedirs('graficos', exist_ok=True)\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0061b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                PASSO 1 — Análise Exploratória de Dados (EDA)\n",
    "# ============================================================\n",
    "\n",
    "# Nesta etapa, realizamos uma avaliação inicial do conjunto de dados com o objetivo de compreender melhor suas características e identificar\n",
    "# padrões importantes para o problema de detecção de fraudes. Foram analisadas as distribuições das variáveis, a presença de valores \n",
    "# extremos, o comportamento das transações ao longo do tempo e as diferenças entre operações\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Visualizar as primeiras 5 linhas do dataset\n",
    "dataset.head()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3864f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Visualizar as Colunas do dataset\n",
    "dataset.info()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98778f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Estatísticas descritivas\n",
    "# Mostra medidas como média, desvio padrão, mínimos, máximos e quartis das variáveis numéricas.\n",
    "# Útil para entender a distribuição dos dados, detectar outliers e avaliar necessidade de normalização.\n",
    "\n",
    "dataset.describe()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Contagem de classes\n",
    "# Mostra quantas transações pertencem a cada classe (0 = não fraude, 1 = fraude).\n",
    "# Útil para verificar o desbalanceamento do dataset e entender a proporção de fraudes.\n",
    "\n",
    "print(dataset['class'].value_counts())\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Distribuição das classes\n",
    "# Cria um gráfico de barras mostrando a quantidade de transações por classe\n",
    "# (0 = não fraude, 1 = fraude).\n",
    "# Útil para visualizar o desbalanceamento do dataset e confirmar a baixa proporção de fraudes.\n",
    "# Os números exatos de casos são exibidos no topo de cada barra.\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = sns.countplot(x='class', data=dataset, palette=\"viridis\")\n",
    "plt.title(\"Distribuição das classes (0 = não fraude, 1 = fraude)\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Quantidade de transações\")\n",
    "plt.savefig('graficos/Distribuicao_classes.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Adicionar valores exatos em cima das barras\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Boxplot do valor das transações\n",
    "# Mostra a distribuição dos valores das transações, destacando concentração em valores baixos e presença de outliers.\n",
    "# Além do boxplot, adiciona os principais valores estatísticos (mínimo, quartis e máximo) diretamente no gráfico.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.boxplot(x=dataset['amount'], color=\"skyblue\")\n",
    "plt.title(\"Boxplot do valor das transações\")\n",
    "plt.savefig('graficos/Boxplot do valor das transações.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Estatísticas\n",
    "stats = dataset['amount'].describe()\n",
    "\n",
    "# Posições Y separadas (evita bagunça)\n",
    "y_positions = {\n",
    "    'min': 0.15,\n",
    "    '25%': 0.35,\n",
    "    '50%': 0.45,\n",
    "    '75%': 0.55,\n",
    "    'max': 0.65\n",
    "}\n",
    "\n",
    "# Adicionar anotações sem empilhar tudo\n",
    "for stat_name, stat_value in stats[['min','25%','50%','75%','max']].items():\n",
    "    ax.annotate(\n",
    "        f\"{stat_name}: {stat_value:.2f}\",\n",
    "        xy=(stat_value, 0),\n",
    "        xytext=(stat_value, y_positions[stat_name]),\n",
    "        textcoords='data',\n",
    "        ha='center',\n",
    "        fontsize=9,\n",
    "        fontweight='bold',\n",
    "        rotation=45,\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"black\")\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ee762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Distribuição do tempo das transações\n",
    "# Cria um histograma para visualizar a frequência de transações ao longo do tempo (em segundos).\n",
    "# Útil para identificar picos de atividade, padrões temporais e possíveis concentrações de transações.\n",
    "# O gráfico foi ajustado com estilo consistente e contagem exata no topo de cada barra.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.histplot(dataset['time'], bins=100, kde=False, color=\"skyblue\")\n",
    "plt.title(\"Distribuição do tempo das transações\")\n",
    "plt.xlabel(\"Segundos desde o início da coleta\")\n",
    "plt.ylabel(\"Quantidade de transações\")\n",
    "plt.savefig('graficos/Distribuição do tempo das transações.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Adicionar valores exatos no topo de cada barra\n",
    "for patch in ax.patches:\n",
    "    height = patch.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f'{int(height)}',\n",
    "                    (patch.get_x() + patch.get_width() / 2, height),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=8, fontweight='bold', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Matriz de correlação entre variáveis (somente numéricas)\n",
    "# Remove colunas não numéricas (como 'periodo') e calcula a correlação apenas entre variáveis numéricas.\n",
    "# Útil para identificar relações lineares entre atributos quantitativos e a variável alvo (class).\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "corr = dataset.select_dtypes(include=['number']).corr()\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 6},   # texto menor = heatmap mais legível\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "plt.title(\"Matriz de correlação entre variáveis (numéricas)\", fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=6)\n",
    "plt.yticks(rotation=0, fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e16a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Criar coluna (hora) a partir da variável (time)\n",
    "dataset['hora'] = dataset['time'] / 3600\n",
    "\n",
    "def periodo_do_dia(hora):\n",
    "    hora = int(hora % 24)  # garante que fique dentro de 0–23h\n",
    "    if 6 <= hora < 12:\n",
    "        return 'manhã'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'tarde'\n",
    "    elif 18 <= hora < 24:\n",
    "        return 'noite'\n",
    "    else:\n",
    "        return 'madrugada'\n",
    "\n",
    "# Criar coluna categórica (periodo)\n",
    "dataset['periodo'] = dataset['hora'].apply(periodo_do_dia)\n",
    "\n",
    "# One-hot encoding limpo\n",
    "dataset_encoded = pd.get_dummies(dataset, columns=['periodo'], prefix='periodo')\n",
    "\n",
    "# ======= GRÁFICO DE CORRELAÇÃO AJUSTADO =======\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "corr = dataset_encoded.corr()\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 8},       # deixa legível\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.7}     # barra menor\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Matriz de Correlação entre Variáveis (com período codificado)\",\n",
    "    fontsize=16,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salvar na pasta já criada\n",
    "plt.savefig(\n",
    "    'graficos/matriz_correlacao_periodo.png',\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51697823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Distribuição das transações por hora\n",
    "# Converte o tempo de segundos para horas e agrupa por hora inteira.\n",
    "# Mostra em gráfico de barras o volume de transações ao longo das 48 horas de coleta.\n",
    "# Útil para identificar picos de atividade e padrões temporais.\n",
    "# Os números exatos de transações são exibidos no topo de cada barra.\n",
    "# Converter tempo para horas\n",
    "dataset['hora'] = dataset['time'] / 3600\n",
    "\n",
    "# Agrupar por hora inteira\n",
    "dataset['hora_inteira'] = dataset['hora'].astype(int)\n",
    "horas = dataset['hora_inteira'].value_counts().sort_index()\n",
    "\n",
    "# Plotar gráfico de barras\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(x=horas.index, y=horas.values, palette=\"viridis\")\n",
    "plt.title(\"Distribuição das transações por hora\")\n",
    "plt.savefig('graficos/Distribuição das transações por hora.png', dpi=300, bbox_inches='tight')\n",
    "plt.xlabel(\"Hora desde o início da coleta\")\n",
    "plt.ylabel(\"Quantidade de transações\")\n",
    "\n",
    "# Adicionar número exato de transações no topo de cada barra com rotação\n",
    "for i, val in enumerate(horas.values):\n",
    "    plt.text(i, val + 100, str(val), ha='center', va='bottom', fontsize=9, fontweight='bold', rotation=45)\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=9)  # mantém as horas na horizontal\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Distribuição das transações por período do dia\n",
    "# Converte o tempo em horas e classifica em ciclos de 24h (madrugada, manhã, tarde, noite).\n",
    "# Cria uma nova coluna 'periodo' e conta a quantidade de transações em cada faixa.\n",
    "# Útil para identificar padrões de atividade em diferentes períodos do dia.\n",
    "# Os valores exatos são exibidos no topo de cada barra.\n",
    "\n",
    "# Converter segundos em horas\n",
    "dataset['hora'] = dataset['time'] / 3600\n",
    "\n",
    "# Função para categorizar períodos do dia\n",
    "def periodo_do_dia(hora):\n",
    "    hora = int(hora % 24)  # ciclo de 24h\n",
    "    if 6 <= hora < 12:\n",
    "        return 'manhã'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'tarde'\n",
    "    elif 18 <= hora < 24:\n",
    "        return 'noite'\n",
    "    else:\n",
    "        return 'madrugada'\n",
    "\n",
    "# Criar coluna de período\n",
    "dataset['periodo'] = dataset['hora'].apply(periodo_do_dia)\n",
    "\n",
    "# Contar transações por período\n",
    "periodos = dataset['periodo'].value_counts().reindex(['madrugada','manhã','tarde','noite'])\n",
    "\n",
    "# Plotar gráfico\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=periodos.index, y=periodos.values, palette=\"viridis\")\n",
    "plt.title(\"Distribuição das transações por período do dia\")\n",
    "plt.savefig('graficos/Distribuição das transações por período do dia.png', dpi=300, bbox_inches='tight')\n",
    "plt.xlabel(\"Período do dia\")\n",
    "plt.ylabel(\"Quantidade de transações\")\n",
    "\n",
    "# Adicionar valores exatos em cima das barras\n",
    "for i, val in enumerate(periodos.values):\n",
    "    plt.text(i, val + 500, str(val), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5af82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                PASSO 2 — PRÉ-PROCESSAMENTO\n",
    "# ============================================================\n",
    "\n",
    "# O pré-processamento prepara o dataset para que o modelo aprenda de forma correta, eliminando \n",
    "# problemas como escalas diferentes, dados extremos e desbalanceamento. No nosso caso, serão aplicados os seguintes processos:\n",
    "# ============================================================\n",
    "\n",
    "# 2.1 — Verificação de valores ausentes\n",
    "# 2.2 — Tratamento de valores ausentes\n",
    "# 2.3 — Normalização (padronização) das colunas \"amount\" e \"time\"\n",
    "# 2.4 — Remoção de outliers\n",
    "# 2.5 — Balanceamento das classes\n",
    "# 2.6 — Separação final em treino e testes\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "#2.1 - Verificar valores ausentes\n",
    "print(\"Valores ausentes por coluna:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e66a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "#2.2 - Remove linhas com valores ausentes (caso existam)\n",
    "dataset = dataset.dropna()\n",
    "print(\"\\nApós remoção de valores ausentes:\", dataset.shape)\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72bb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 2.3 — Normalização das colunas Amount e Time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#Esse objeto calcula:\n",
    "#média da coluna\n",
    "#desvio padrão\n",
    "#e transforma os valores usando a função z = (x - média) / desvio padrão\n",
    "\n",
    "dataset[['amount_scaled', 'time_scaled']] = scaler.fit_transform(dataset[['amount', 'time']])\n",
    "#média = 0\n",
    "#desvio padrão = 1\n",
    "#deixam o dataset mais adequado para treinar\n",
    "\n",
    "print(\"\\nColunas normalizadas adicionadas (amount_scaled, time_scaled).\")\n",
    "#Agora o dataset possui:\n",
    "#amount_scaled\n",
    "#time_scaled\n",
    "#otal de 33 colunas agora.\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 2.4 — Remover outliers da coluna 'amount'\n",
    "# O dataset tem transações com valores muito altos, removemos extremos\n",
    "# usando a técnica IQR (Intervalo Inter-Quartil).\n",
    "Q1 = dataset['amount'].quantile(0.25)\n",
    "Q3 = dataset['amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "dataset = dataset[\n",
    "    (dataset['amount'] >= limite_inferior) &\n",
    "    (dataset['amount'] <= limite_superior)\n",
    "]\n",
    "\n",
    "print(\"\\nApós remoção de outliers:\", dataset.shape)\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 2.5 - Balanceamento das classes com SMOTE\n",
    "# O dataset é extremamente desbalanceado (fraudes ≈ 0.17%)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separar atributos (X) e rótulo (y)\n",
    "# Removemos 'class' (alvo) e 'periodo' (categórica) para evitar erro no SMOTE\n",
    "X = dataset.drop(['class', 'periodo'], axis=1)\n",
    "y = dataset['class']\n",
    "\n",
    "# O SMOTE cria novos exemplos sintéticos da classe minoritária (fraudes),\n",
    "# usando interpolação entre vizinhos próximos. Isso evita overfitting e\n",
    "# deixa as duas classes com o mesmo número de amostras.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Mostrar distribuição antes e depois do balanceamento\n",
    "print(\"\\nDistribuição antes do SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "print(\"\\nDistribuição depois do SMOTE:\")\n",
    "print(y_resampled.value_counts())\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 2.6 — Separar os dados em treino e teste\n",
    "# Usamos 80% para treino e 20% para teste\n",
    "\n",
    "# Até aqui aplicamos SMOTE, então o dataset ficou balanceado:\n",
    "# Classe 0 - 234.554\n",
    "# Classe 1 - 234.554\n",
    "# Total após SMOTE = 469.108 registros (aproximadamente)\n",
    "#\n",
    "# Depois dividimos os dados em:\n",
    "# 80% para TREINO - modelo aprende\n",
    "# 20% para TESTE  - modelo é avaliado\n",
    "#\n",
    "# OBS: os valores finais podem variar um pouco porque o SMOTE\n",
    "# cria amostras sintéticas usando vizinhos próximos.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTamanho do conjunto de treino:\", X_train.shape)\n",
    "print(\"Tamanho do conjunto de teste:\", X_test.shape)\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Boxplot dos valores por classe\n",
    "# Verifica se os outliers da coluna (amount) estão associados à classe de fraude.\n",
    "# A análise mostra que os valores extremos estão majoritariamente na classe 0 (não fraude),\n",
    "# indicando que os outliers não representam transações fraudulentas.\n",
    "# Portanto, a remoção desses outliers foi considerada adequada para reduzir ruído sem\n",
    "# comprometer a detecção de fraudes.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='class', y='amount', data=dataset)\n",
    "plt.title(\"Distribuição dos valores por classe (0 = não fraude, 1 = fraude)\")\n",
    "plt.savefig('graficos/Distribuição dos valores por classe (0 = não fraude, 1 = fraude).png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab5ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. MODELAGEM — Treinamento de três algoritmos\n",
    "# ============================================\n",
    "\n",
    "# MODELO 1: KNN (K-Nearest Neighbors)\n",
    "# MODELO 2: ÁRVORE DE DECISÃO (Decision Tree)\n",
    "# MODELO 3: Random Forest\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ========================================================\n",
    "# MODELO 1: KNN\n",
    "# ========================================================\n",
    "\n",
    "# ========================================================\n",
    "# O KNN classifica uma transação verificando os vizinhos\n",
    "# mais próximos no espaço de atributos. É simples e serve\n",
    "# como baseline para comparar com outros modelos.\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_proba_knn = knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n===== RESULTADOS DO MODELO KNN =====\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_knn))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# MODELO 2: ÁRVORE DE DECISÃO (Decision Tree)\n",
    "# ========================================================\n",
    "# A árvore de decisão cria regras de decisão para classificar\n",
    "# cada transação. É rápida, interpretável e eficiente.\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "y_proba_tree = tree.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n===== RESULTADOS DO MODELO DECISION TREE =====\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_tree))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_tree))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_tree))\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a96669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# MODELO 3: Random Forest\n",
    "# ========================================================\n",
    "# Árvores de decisão treinadas com amostras/atributos distintos.\n",
    "# Geralmente reduz overfitting da árvore única e é muito eficaz em dados tabulares.\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,       # reduz número de árvores\n",
    "    min_samples_leaf=10,    # folhas maiores, menos complexidade\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n===== RESULTADOS DO MODELO RANDOM FOREST =====\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f57b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# 5. Comparação \n",
    "# =============================================================\n",
    "\n",
    "# Nesta etapa, comparamos os três modelos aplicados: KNN, Decision Tree e Random Forest, avaliando desempenho\n",
    "# limitações, robustez e aplicabilidade no contexto de detecção de fraudes. A análise considera não apenas métricas quantitativas\n",
    "# mas também aspectos conceituais importantes para uso real em produção.\n",
    "\n",
    "# Os três modelos apresentaram bons resultados, porém o Random Forest demonstrou\n",
    "# superioridade em praticamente todas as métricas, além de ser mais estável e robusto. \n",
    "# O modelo é altamente eficaz para o cenário proposto de detecção de fraudes, embora melhorias adicionais possam tornar a solução ainda mais precisa e generalizável.\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c326a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Importância de features\n",
    "# ========================================================\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 features por importância:\\n\", importances.head(10))\n",
    "\n",
    "# ========================================================\n",
    "# Validação cruzada com 3 folds (Random Forest otimizado)\n",
    "# ========================================================\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf, X_resampled, y_resampled, cv=cv, scoring='f1')\n",
    "print(\"\\nF1 médio (Random Forest, CV=3):\", scores.mean())\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a657401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Curva ROC comparativa\n",
    "# ========================================================\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_proba_knn)\n",
    "fpr_tree, tpr_tree, _ = roc_curve(y_test, y_proba_tree)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "\n",
    "plt.plot(fpr_knn, tpr_knn, label=f\"KNN (AUC = {roc_auc_score(y_test, y_proba_knn):.3f})\")\n",
    "plt.plot(fpr_tree, tpr_tree, label=f\"Decision Tree (AUC = {roc_auc_score(y_test, y_proba_tree):.3f})\")\n",
    "plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {roc_auc_score(y_test, y_proba_rf):.3f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')  # linha diagonal\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC Comparativa dos Modelos\")\n",
    "plt.savefig('graficos/Curva ROC Comparativa dos Modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34179fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Comparação final em tabela\n",
    "# ========================================================\n",
    "\n",
    "# - MODELO 3: Random Forest é o melhor modelo entre os três, com quase 100% de acurácia, recall e precisão.\n",
    "# - Modelo extremamente robusto e confiável\n",
    "\n",
    "# - MODELO 2: ÁRVORE DE DECISÃO - também teve desempenho excelente, porém, pode estar um pouco especialista demais (overfitting leve).\n",
    "\n",
    "# - MODELO 1: KNN (K-Nearest Neighbors) funciona, mas é inferior e menos escalável, funciona comparando cada amostra com seus vizinhos mais próximos.\n",
    "\n",
    "\n",
    "comparacao = pd.DataFrame({\n",
    "    \"Modelo\": [\"KNN\", \"Decision Tree\", \"Random Forest\"],\n",
    "    \"Acurácia\": [\n",
    "        accuracy_score(y_test, y_pred_knn),\n",
    "        accuracy_score(y_test, y_pred_tree),\n",
    "        accuracy_score(y_test, y_pred_rf)\n",
    "    ],\n",
    "    \"ROC AUC\": [\n",
    "        roc_auc_score(y_test, y_proba_knn),\n",
    "        roc_auc_score(y_test, y_proba_tree),\n",
    "        roc_auc_score(y_test, y_proba_rf)\n",
    "    ],\n",
    "    \"Resumo\": [\n",
    "        \"Bom, mas mais fraco e lento em grandes bases\",\n",
    "        \"Excelente, mas pode sobreajustar\",\n",
    "        \"Melhor modelo, quase nenhuma fraude perdida\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nComparação final:\\n\", comparacao)\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# As matrizes de confusão permitem avaliar visualmente os acertos e erros de cada modelo.\n",
    "# Elas mostram quantas transações legítimas (classe 0) e fraudulentas (classe 1) foram\n",
    "# corretamente classificadas (diagonal principal) e quantas foram confundidas (fora da diagonal).\n",
    "# Esse tipo de gráfico complementa as métricas numéricas (acurácia, precisão, recall, F1, ROC AUC),\n",
    "# oferecendo uma visão intuitiva da capacidade dos modelos em distinguir fraude vs não fraude.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Função para plotar matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred, titulo):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(titulo)\n",
    "    plt.savefig('graficos/Matriz de Confusão - KNN.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig('graficos/Matriz de Confusão - Decision Tree.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig('graficos/Matriz de Confusão - Random Forest.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Matriz de confusão para cada modelo\n",
    "plot_confusion_matrix(y_test, y_pred_knn, \"Matriz de Confusão - KNN\")\n",
    "plot_confusion_matrix(y_test, y_pred_tree, \"Matriz de Confusão - Decision Tree\")\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Matriz de Confusão - Random Forest\")\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d35732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Como melhoria implementamos um algoritmo mais avançado: XGBoost, resultando nos dados abaixo:\n",
    "\n",
    "# ========================================================\n",
    "# MODELO 4: XGBoost\n",
    "# ========================================================\n",
    "# O XGBoost é um algoritmo de boosting baseado em árvores de decisão.\n",
    "# Ele constrói várias árvores sequenciais, onde cada nova árvore corrige\n",
    "# os erros da anterior. É altamente eficiente e costuma ter desempenho\n",
    "# superior em problemas de classificação tabular.\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Instanciar o modelo com hiperparâmetros básicos\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,        # número de árvores\n",
    "    learning_rate=0.1,       # taxa de aprendizado\n",
    "    max_depth=6,             # profundidade máxima das árvores\n",
    "    subsample=0.8,           # fração de amostras usadas em cada árvore\n",
    "    colsample_bytree=0.8,    # fração de atributos usados em cada árvore\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\"    # evita warnings\n",
    ")\n",
    "\n",
    "# 2) Treinar o modelo\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# 3) Fazer previsões\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 4) Avaliar desempenho com métricas\n",
    "print(\"\\n===== RESULTADOS DO MODELO XGBOOST =====\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_xgb))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "# 5) Plotar matriz de confusão\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_xgb, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusão - XGBoost\")\n",
    "plt.savefig('graficos/Matriz de Confusão - XGBoost.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6) Curva ROC exclusiva do XGBoost\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_proba_xgb)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f\"XGBoost (AUC = {roc_auc_score(y_test, y_proba_xgb):.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - XGBoost\")\n",
    "plt.savefig('graficos/Curva ROC - XGBoost.png', dpi=300, bbox_inches='tight')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7) Importância das features\n",
    "importances_xgb = pd.Series(xgb.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 features por importância (XGBoost):\\n\", importances_xgb.head(10))\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad469db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Comparação de métricas entre os quatro modelos implementados: KNN, Decision Tree, Random Forest e XGBoost. \n",
    "import pandas as pd\n",
    "\n",
    "# Criar DataFrame com métricas comparativas\n",
    "comparacao = pd.DataFrame({\n",
    "    \"Modelo\": [\"KNN\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Acurácia\": [\n",
    "        accuracy_score(y_test, y_pred_knn),\n",
    "        accuracy_score(y_test, y_pred_tree),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    \"ROC AUC\": [\n",
    "        roc_auc_score(y_test, y_proba_knn),\n",
    "        roc_auc_score(y_test, y_proba_tree),\n",
    "        roc_auc_score(y_test, y_proba_rf),\n",
    "        roc_auc_score(y_test, y_proba_xgb)\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"\\nTabela comparativa de métricas:\\n\")\n",
    "print(comparacao)\n",
    "\n",
    "# ========================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
